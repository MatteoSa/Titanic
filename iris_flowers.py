# -*- coding: utf-8 -*-
"""IRIS_Flowers

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PtKQRW4kyCsfj187ZpY7yx96fU242uQ1
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.model_selection import cross_validate
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from joblib import dump
#Import Libraries

#Import the dataset
df=pd.read_csv("/content/IRIS_ Flower_Dataset.csv")

df

df.info()

df.isnull().sum()

df.describe()

df['species'].value_counts()

#Show the mean of Sepal Length by Species
moyenne_par_espece = df.groupby('species')['sepal_length'].mean()
moyenne_par_espece.plot(kind='bar', rot=45, color='skyblue', legend=False)
plt.title('Mean of Sepal Length by Species')
plt.xlabel('Species')
plt.ylabel('Mean of Sepal Length')
plt.show()

#Show the mean of Sepal Width by Species
moyenne_par_espece = df.groupby('species')['sepal_width'].mean()
moyenne_par_espece.plot(kind='bar', rot=45, color='red', legend=False)
plt.title('Mean of Sepal width by Species')
plt.xlabel('Species')
plt.ylabel('Mean of Sepal width')
plt.show()

#Show the mean of Petal Length by Species
moyenne_par_espece = df.groupby('species')['petal_length'].mean()
moyenne_par_espece.plot(kind='bar', rot=45, color='darkblue', legend=False)
plt.title('Mean of Petal Length by Species')
plt.xlabel('Species')
plt.ylabel('Mean of Petal Length')
plt.show()

#Show the mean of Petal Width by Species
moyenne_par_espece = df.groupby('species')['petal_width'].mean()
moyenne_par_espece.plot(kind='bar', rot=45, color='green', legend=False)
plt.title('Mean of Petal Width by Species')
plt.xlabel('Species')
plt.ylabel('Mean of Petal Width')
plt.show()

plt.figure(figsize=(15, 10))
pairplot = sns.pairplot(df, hue='species', markers=["o", "s", "D"], palette="Set2", height=2, diag_kind='kde')

plt.suptitle("Pairplots with KDE for Iris Features by Species", y=1.02)
plt.show()

#Create 2 sets one with the values and the other with the name of the flower
X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]
y = df['species']

# Convert the data into a numerical value
y = pd.Categorical(y).codes

# Split data into 2 sets training and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create random forest model
random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)

# Training the model with training data
random_forest_model.fit(X_train, y_train)
predictions = random_forest_model.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
print(f'Accuracy: {accuracy:.2f}')

#Using cross validation
cv_results = cross_validate(random_forest_model, X, y, cv=5, return_train_score=True)

# Show the score of each fold
print("Train Scores:", cv_results['train_score'])
print("Test Scores:", cv_results['test_score'])

pipeline = make_pipeline(StandardScaler(), RandomForestClassifier(random_state=42))
#Create a list with parameters to test
param_grid = {
    'randomforestclassifier__n_estimators': [50,100,200],
    'randomforestclassifier__max_depth': [None, 10, 20, 30],
    'randomforestclassifier__min_samples_split': [2, 5, 10],
    'randomforestclassifier__min_samples_leaf': [1, 2, 4]
}
# Search for the best hyper parameters
grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')
# Modify the model with the best hyper parameters
grid_search.fit(X_train, y_train)

# Show best hyperparameters
print("Best hyperparameters:", grid_search.best_params_)

# Predict the best model on the data test
predictions = grid_search.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, predictions)
print(f'Accuracy: {accuracy:.2f}')

feature_importances = random_forest_model.feature_importances_
features = X.columns

# Create a DataFrame to visualise
importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})
importance_df = importance_df.sort_values(by='Importance', ascending=False)

# Shox the graphic
plt.figure(figsize=(10, 6))
plt.bar(importance_df['Feature'], importance_df['Importance'], color='blue')
plt.xlabel('Features')
plt.ylabel('Importance')
plt.title('Importance of the features in the Random Forest')
plt.show()

train_scores = cv_results['train_score']
test_scores = cv_results['test_score']

plt.figure(figsize=(10, 5))
plt.plot(range(1, 6), train_scores, marker='o', label='Train Score', linestyle='-', color='blue')
plt.plot(range(1, 6), test_scores, marker='o', label='Test Score', linestyle='-', color='green')
plt.title('Evaluate the model with cross validation')
plt.xlabel('Folds')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

#Create the confusion matrix
conf_matrix = confusion_matrix(y_test, predictions)

# Show the confusion matrix with seaborn
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=df['species'].unique(), yticklabels=df['species'].unique())
plt.title('Confusion Matrix')
plt.xlabel('Predictions')
plt.ylabel('True Values')
plt.show()

#Save the model
dump(random_forest_model, 'modele_random_forest.joblib')

